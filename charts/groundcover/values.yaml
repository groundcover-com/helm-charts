global:
  groundcover_token:
  # groundcover_token is preceding groundcoverPredefinedTokenSecret, make sure its empty if using existing secret
  # if the secret is preloaded in the namespace, you can refer it here instead
  # example for a preloaded secret :
  # apiVersion: v1
  # kind: Secret
  # metadata:
  #   name: <secretName>
  # stringData:
  #   <secretKey>: <apikey>
  # type: Opaque
  groundcoverPredefinedTokenSecret:
    # the name of the secret
    secretName:
    # the key in the secret containing the token value
    secretKey:
  
  groundcoverLabels:
  
metrics:
  enabled: true

logging:
  enabled: true
  host: logs.groundcover.com
  scheme: https

# SAAS parameters, token is mendatory, others only if in cloud mode
saas:
  tls_skip_verify: false
  scheme: wss
  host: app.groundcover.com
  port: 443

#GENERAL
clusterId:
# multipleClusterIds:
#  - clusterA
#  - clusterB
region:
filteredNamespaces: []
shouldDropRunningNamespaces: true

origin:
  registry: public.ecr.aws/groundcovercom
  tag: 0.37.3

pullSecrets: []

backend:
  enabled: true

agent:
  enabled: true
  additionalLabels:
  podLabels:
  additionalAnnotations:
  podAnnotations:
  tolerations: []
  affinity:
  nodeSelector:
  priorityClassName:
  alligator:
    repository: alligator
    resources:
      requests:
        memory: 128Mi
        cpu: 100m
      limits:
        memory: 350Mi
        cpu: 500m
    obfuscateData: false
    dataRetention: 12h
    nodelabels: []
    contentTypesToDrop: ["text/html", "text/javascript", "text/css", "image", "font", "video", "audio"]
    watchOnlyLocalNode: true
    env:
  tracy:
    repository: tracy
    resources:
      requests:
        memory: 512Mi
        cpu: 125m
      limits:
        memory: 2048Mi
        cpu: 750m
  promtail:
    repository: promtail
    resources:
      requests:
        cpu: 40m
        memory: 128Mi
      limits:
        cpu: 200m
        memory: 256Mi
  flb:
    resources:
      requests:
        cpu: 20m
        memory: 32Mi
      limits:
        cpu: 100m
        memory: 64Mi
        
  fetchLinuxHeaders:
    enabled: false
    repository: fetch-linux-headers

migrator:
  additionalLabels:
  podLabels:
  additionalAnnotations:
  podAnnotations:
  affinity:
  nodeSelector:
  tolerations: 
  priorityClassName:
  resetDB: "false" # must be string
  repository: migrator

k8sWatcher:
  repository: k8s-watcher
  additionalLabels:
  podLabels:
  additionalAnnotations:
  podAnnotations:
  affinity:
  nodeSelector:
  tolerations: []
  priorityClassName:
  resources:
    limits:
      cpu: 100m
      memory: 200Mi
    requests:
      cpu: 50m
      memory: 100Mi
  env:

portal:
  additionalLabels:
  podLabels:
  additionalAnnotations:
  podAnnotations:
  affinity:
  nodeSelector:
  tolerations: []
  priorityClassName:
  repository: portal
  resources:
    limits:
      cpu: 100m
      memory: 200Mi
    requests:
      cpu: 50m
      memory: 100Mi

loki:
  # loki pullSecrets expects the secret name only, instead of `- name: {secret}` just `- {secret}`
  # image:
  #   pullSecrets: [] 

  affinity:

  nodeSelector:

  tolerations: []

  podLabels: {}

  ## StatefulSet annotations
  annotations: {}

  resources:
    requests:
      cpu: 250m
      memory: 750Mi
    limits:
      memory: 3000Mi
      cpu: 1000m

  persistence:
    enabled: true
    size: 10Gi
    annotations: {}
    storageClassName:
    # -- Use this to override the prefix for the pvc, the suffix is auto-generated by k8s according to the pod name
    pvcNameOverride:
  
  # NFS alternative to persistentVolume, mutual exclusive with persistence.enabled
  #  nfs:
  #   enabled: false
  #   server:
  #   path:

  # overrideURL:
  # ingress:
  #   enabled: false
  #   # For Kubernetes >= 1.18 you should specify the ingress-controller via the field ingressClassName
  #   # See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#specifying-the-class-of-an-ingress
  #   # ingressClassName: nginx
  #   annotations: {}
  #     # kubernetes.io/ingress.class: nginx
  #     # kubernetes.io/tls-acme: "true"
  #   hosts:
  #     - host: chart-example.local
  #       paths: []
  #   tls: []
  #   #  - secretName: chart-example-tls
  #   #    hosts:
  #   #      - chart-example.local
  
  config:
    table_manager:
      retention_period: 2h

  service:
    annotations: {}
    labels: {}
    clusterIP:

  priorityClassName:

grafana:
  additionalLabels:
  podLabels:
  additionalAnnotations:
  podAnnotations:
  enabled: true
  nameOverride:
  repository: grafana
  storageClassName:
  affinity:
  nodeSelector:
  tolerations: []
  priorityClassName:
  resources:
    requests:
      cpu: 250m
      memory: 750Mi
    limits:
      memory: 1000Mi
      cpu: 1000m
  clusterIP:

router:
# onprem or cloud
  mode: cloud
  enabled: false
  additionalLabels:
  additionalAnnotations:
  repository: router
  origin:
    registry: public.ecr.aws/groundcovercom
    tag: 0.37.3

# These are the recomendded presets
# if you are after an uninstallation, prior to re-installation make sure
# you've deleted the pvcs:  kubectl delete pvc wal-volume-<release-name>-groundcover-tsdb-0  server-volume-<release-name>-groundcover-tsdb-0 
# you've deleted the endpoints:
# kubectl delete svc <release_name>-config
# kubectl delete endpoints <release_name>
# if you installed groundcover in its own namespace, deleting the namespace can done instead
timescaledb-single:
  # imagePullSecrets: []
  tolerations: []
  podAnnotations: {}
  nodeSelector: {}
  #affinity: {} 
  # -- Name of Priority Class
  priorityClassName:
  service:
    primary:
      lables: {}
      annotations: {}
      clusterIP:

  # NFS alternative to persistentVolume, mutual exclusive with persistentVolume.data.enabled and persistentVolume.wal.enabled
  # nfs:
  #   enabled: false
  #   server:
  #   path:

  persistentVolumes:

    data:
      # enabled: true
      storageClass:
      size: 100Gi
      annotations: {}
      # -- Use this to override the prefix for the pvc, the suffix is auto-generated by k8s according to the pod name
      #pvcNameOverride:
      # NFS option for the data storage, mutual exclusive with  data.enabled

    wal: 
      # enabled: true
      storageClass:
      size: 10Gi
      annotations: {}
      # -- Use this to override the prefix for the pvc, the suffix is auto-generated by k8s according to the pod name
      #pvcNameOverride: 

  resources:
    requests:
      cpu: 1000m
      memory: 2000Mi
    limits:
      cpu: 1000m
      memory: 2000Mi
  
  job:
    tolerations: []
    nodeSelector: {}
    affinity: {}

  # By default the timescaledb secrets are randomly generated, and are re-using the existing values incase of using `helm upgrade`
  # in case of a re-installation (uninstall and install), the wal-* and storage-* pvcs must be deleted as well.
  # if you are interested in upgrading an existing installation using a different toolkit from helm, that uses helm template,
  # you can state the existing secret, in our vanilla installation its name is groundcover-tsdb-certificate
  secrets:
    credentialsSecretName: "" 

# victoria-metrics-agent:
#   imagePullSecrets:

victoria-metrics-single:
  # imagePullSecrets: []
  server:
    # -- Data retention period, {amount}[h(ours), d(ays), w(eeks), y(ears)], default is 1 month
    retentionPeriod: 7d
    # -- Sts/Deploy additional labels
    extraLabels: {}
    # -- Pod's additional labels
    podLabels: {}
    # -- Pod's annotations
    podAnnotations: {}

    # -- Name of Priority Class
    priorityClassName:

    service:
      # -- Service annotations
      annotations: {}
      # -- Service labels
      labels: {}
      # -- Service ClusterIP
      clusterIP: None
    
    matchLabels: {}
    
    statefulSet:
      annotations: {}
      # -- Headless service labels
      labels: {}

    persistentVolume:    
      # enabled: true
      # -- Persistant volume annotations
      annotations: {}

      # -- StorageClass to use for persistent volume. Requires server.persistentVolume.enabled: true. If defined, PVC created automatically
      storageClass:

      # -- Use this to override the prefix for the pvc, the suffix is auto-generated by k8s according to the pod name
      #pvcNameOverride:

      size: 100Gi

    # NFS alternative to persistentVolume, mutual exclusive with persistentVolume.enabled
    # nfs:
    #   enabled: false
    #   server:
    #   path:

    resources:            
      requests:
        cpu: 1000m
        memory: 3000Mi
      limits:
        cpu: 1000m
        memory: 3000Mi

    # -- Node tolerations for server scheduling to nodes with taints. Ref: [https://kubernetes.io/docs/concepts/configuration/assign-pod-node/](https://kubernetes.io/docs/concepts/configuration/assign-pod-node/)
    tolerations: []

    # -- Pod's node selector. Ref: [https://kubernetes.io/docs/user-guide/node-selection/](https://kubernetes.io/docs/user-guide/node-selection/)
    nodeSelector: {}

    # -- Pod affinity
    affinity: {}

promscale:
  repository: promscale
  nameOverride: groundcover-promscale
  fullnameOverride: groundcover-promscale

  imagePullPolicy: IfNotPresent
  # number of connector pods to spawn
  replicaCount: 1

  # Override the deployment namespace
  namespaceOverride: ""

  # Promscale deployment upgrade strategy
  # as Promscale upgrade requires no existing Promscale
  # connected with TimescaleDB. Recreate strategy helps
  # scale down to 0 and recreate the new version.
  upgradeStrategy: Recreate

  # overridePromURL:
  promIngress:
    enabled: false
    # For Kubernetes >= 1.18 you should specify the ingress-controller via the field ingressClassName
    # See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#specifying-the-class-of-an-ingress
    # ingressClassName: nginx
    annotations: {}
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"
    hosts:
      - host: chart-example.local
        paths: []
    tls: []
    #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local
    
  # overrideOtelURL:
  otelIngress:
    enabled: false
    # For Kubernetes >= 1.18 you should specify the ingress-controller via the field ingressClassName
    # See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#specifying-the-class-of-an-ingress
    # ingressClassName: nginx
    annotations: {}
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"
    hosts:
      - host: chart-example.local
        paths: []
    tls: []
    #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local


  # Arguments that will be passed onto deployment pods
  # The list of available cli flags is available at
  # https://github.com/timescale/promscale/blob/master/docs/cli.md

  # For example, to activate HA, bump the replicaCount and set those arguments (also, make sure that external labels are configured on the Prometheus side):
  # - --high-availabiliity=1
  # More info about HA: https://github.com/timescale/promscale/blob/master/docs/high-avaliability/prometheus-HA.md
  extraArgs: []

  # Environment variables that will be passed onto deployment pods
  extraEnv:
    - name: PROMSCALE_AUTH_TLS_CERT_FILE
      value: "/var/groundcover/server/tls.crt"
    - name: PROMSCALE_AUTH_TLS_KEY_FILE
      value: "/var/groundcover/server/tls.key"

  # Currently OpenTelemetry tracing support is in beta
  # so tracing features needs to be explicitly enabled.
  openTelemetry:
    # OpenTelemetry tracing is only enabled if below field is configured true
    enabled: true
    port: 9202

  # selector used to provision your own Secret containing connection details
  # Use this option with caution
  connectionSecretName: ""

  # connection options to connect to a target db
  connection:
    # Database connection settings. If `uri` is not
    # set then the specific user, pass, host, port and
    # sslMode properties are used.
    uri: ""
    # user used to connect to TimescaleDB
    user: postgres
    password: ""
    host: "groundcover-tsdb"
    port: 5432
    sslMode: require
    # database name in which to store the metrics
    # must be created before start
    dbName: groundcover

  # Enable ServiceMonitor used by prometheus-operator to configure prometheus for metrics scraping
  serviceMonitor:
    enabled: false

  # Prometheus annotations to configure scraping metrics from the connector
  prometheus:
    port: 9201
    # Using the predefined annotations from the Prometheus helm chart:
    # https://hub.helm.sh/charts/stable/prometheus
    annotations:
      prometheus.io/scrape: 'true'
      prometheus.io/port: '9201'
      prometheus.io/path: '/metrics'
      prometheus.io/scheme: https

  # settings for the service to be created that will expose
  # the promscale deployment
  service:
    type: "ClusterIP"
    # Read more about the AWS annotations here:
    # https://kubernetes.io/docs/concepts/cluster-administration/cloud-providers/#aws
    # https://docs.aws.amazon.com/eks/latest/userguide/load-balancing.html
    annotations: {}
      # Setting idle-timeout to the maximum allowed value
      # service.beta.kubernetes.io/aws-load-balancer-connection-idle-timeout: "4000"
      # service.beta.kubernetes.io/aws-load-balancer-type: nlb            # Use an NLB instead of ELB
      # service.beta.kubernetes.io/aws-load-balancer-internal: 0.0.0.0/0  # Internal Load Balancer

  # set your own limits
  resources:
    requests:
      cpu: 250m
      memory: 200Mi
    limits:
      cpu: 500m
      memory: 250Mi

  # https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector
  nodeSelector: {}

  # https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  tolerations: []

  # https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity
  affinity: {}

rbac:
  pspEnabled: true
  labels:
  annotations:

apikey:
  labels:
  annotations:

config:
  labels:
  annotations:

vmagent-backend:
  remoteWriteUrls:
    - http://groundcover-victoria-metrics:8428/api/v1/write
  resources:
    limits:
      cpu: 150m
      memory: 256Mi
    requests:
      cpu: 50m
      memory: 128Mi
  extraArgs:
    remoteWrite.maxRowsPerBlock: 15000

  # overrideURL:
  ingress:
    enabled: false
    annotations: {}
    #   kubernetes.io/ingress.class: nginx
    #   kubernetes.io/tls-acme: 'true'

    extraLabels: {}
    hosts: []
    #   - name: vmagent.local
    #     path: /
    #     port: http
    tls: []
    #   - secretName: vmagent-ingress-tls
    #     hosts:
    #       - vmagent.local
    # For Kubernetes >= 1.18 you should specify the ingress-controller via the field ingressClassName
    # See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#specifying-the-class-of-an-ingress
    # ingressClassName: nginx
    # -- pathType is only for k8s >= 1.1=
    pathType: Prefix
  
  service:
    servicePort: 8429
    
# These are presets for low resource enviroments
# timescaledb-single:
#   tolerations: []
#   podAnnotations: {}
#   nodeSelector: {}
#   service:
#     primary:
#       lables: {}
#       annotations: {}
#       clusterIP:
#   persistentVolumes:
#     data:
#       storageClass:
#       size: 10Gi
#       annotations: {}
#     wal: 
#       storageClass:
#       size: 50Gi
#       annotations: {}
#   resources:
#     requests:
#       cpu: 500m
#       memory: 1000Mi
#     limits:
#       cpu: 500m
#       memory: 1000Mi

# victoria-metrics-single:

#   server:
#     # -- Sts/Deploy additional labels
#     extraLabels: {}
#     # -- Pod's additional labels
#     podLabels: {}
#     # -- Pod's annotations
#     podAnnotations: {}

#     service:
#       # -- Service annotations
#       annotations: {}
#       # -- Service labels
#       labels: {}
#       # -- Service ClusterIP
#       clusterIP: ""
    
#     statefulSet:
#       annotations: {}
#       # -- Headless service labels
#       labels: {}

#     persistentVolume:    
#       # -- Persistant volume annotations
#       annotations: {}

#       # -- StorageClass to use for persistent volume. Requires server.persistentVolume.enabled: true. If defined, PVC created automatically
#       storageClass:

#       size: 50Gi

#     resources:            
#       requests:
#         cpu: 500m
#         memory: 1000Mi
#       limits:
#         cpu: 500m
#         memory: 1000Mi

#     # -- Node tolerations for server scheduling to nodes with taints. Ref: [https://kubernetes.io/docs/concepts/configuration/assign-pod-node/](https://kubernetes.io/docs/concepts/configuration/assign-pod-node/)
#     tolerations: []

#     # -- Pod's node selector. Ref: [https://kubernetes.io/docs/user-guide/node-selection/](https://kubernetes.io/docs/user-guide/node-selection/)
#     nodeSelector: {}

#     # -- Pod affinity
#     affinity: {}